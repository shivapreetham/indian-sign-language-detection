# Sign Language Assistant

## ğŸ§  Overview

The **Sign Language Assistant** is a Python-based application aimed at bridging the communication gap for individuals with hearing impairments. It provides two core functionalities:

* **Voice to Sign**: Converts spoken language to visual sign language using GIFs or alphabet signs.
* **Sign Detection**: Detects and interprets real-time sign gestures from webcam input using a trained ML model and MediaPipe.

> The app supports 35 classes focused on **Indian Sign Language (ISL)** using techniques from **Computer Vision**, **Machine Learning**, and **Natural Language Processing**.

---

## ğŸš€ Features

* **ğŸ“¸ Data Collection**: Captures 100 images/class for 35 signs using webcam (in 10-image batches).
* **ğŸ§ª Data Augmentation**: Enhances dataset using brightness/contrast, blur, flips (3x augmentations).
* **ğŸ§¬ Feature Extraction**: Uses **MediaPipe Holistic** landmarks (weighted hands/face/pose) for model input.
* **ğŸ§  Model Training**: Trains a `RandomForestClassifier` with hyperparameter tuning.
* **ğŸ—£ï¸ Voice to Sign**: Google Speech Recognition to ISL GIFs or letters.
* **ğŸ¤Ÿ Sign Detection**: Real-time prediction with buffer-based voting and **Gemini API** interpretation.
* **ğŸ–¥ï¸ UI**: Built with **Tkinter**, interactive and easy to use.

---

## ğŸ”§ Prerequisites

* **Python**: Version 3.8+
* **Webcam**: Required for real-time tasks
* **Gemini API**: Must be running at `http://localhost:8000/gemini` or update in code
* **Image/GIF Assets**:

  * `logo.png`
  * `letters/` folder with `a.jpg` ... `z.jpg`, `empty.jpg`
  * `ISL_Gifs/` with predefined phrases (e.g., `good morning.gif`)

### ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“ Directory Structure

```
sign-language-assistant/
â”œâ”€â”€ data/                      # Collected raw sign images
â”œâ”€â”€ augmented_data/           # Augmented images
â”œâ”€â”€ letters/                  # Alphabet signs (JPGs)
â”œâ”€â”€ ISL_Gifs/                 # Phrase signs (GIFs)
â”œâ”€â”€ logo.png
â”œâ”€â”€ data.pickle               # Extracted features
â”œâ”€â”€ model.p                   # Trained model
â”œâ”€â”€ confusion_matrix.png
â”œâ”€â”€ feature_importances.png
â”œâ”€â”€ image_gallery.html
â”œâ”€â”€ *.py                      # Python scripts
â””â”€â”€ requirements.txt
```

---

## ğŸ’» Usage

### â–¶ Launch App

```bash
python main.py
```

Provides 3 GUI options: `Voice To Sign`, `Sign Detection`, `Exit`

### ğŸ—£ Voice to Sign

* Converts spoken phrases â†’ ISL GIFs or letters
* Displays gallery if no phrase match

### âœ‹ Sign Detection

* Live gesture prediction via webcam
* Buffered voting (15 frames, 60% confidence)
* Press:

  * `G` â€“ Interpret buffered sequence via **Gemini API**
  * `B` â€“ Back
  * `Q` â€“ Quit

---

## ğŸ›  Optional Scripts

### ğŸ“¸ Data Collection

```bash
python data_collection.py
```

Captures 100 images per sign (10/batch)

### ğŸ§ª Data Augmentation

```bash
python data_augmentation.py
```

Generates 3 augmented images per original

### ğŸ“Š Feature Extraction

```bash
python feature_extraction.py
```

Uses MediaPipe Holistic landmarks, saves as `data.pickle`

### ğŸ§  Model Training

```bash
python model_training.py
```

* Trains RandomForest with `GridSearchCV`
* Outputs `model.p`, plots

---

## ğŸ§¬ Technical Details

### ğŸ–¼ï¸ Image Handling

* Stored in `./data/<class>` or `./augmented_data/<class>`
* JPG format

### âš™ï¸ Feature Extraction

* Weights: hand = 1.0, face = 0.1, pose = 0.3
* Normalized using min(x, y)

### ğŸ§  Classifier

* **RandomForestClassifier** + `StandardScaler`
* Parameters: `n_estimators`, `max_depth`, `min_samples_leaf`, `max_features`
* Outputs: `confusion_matrix.png`, `feature_importances.png`

### ğŸ—£ Speech Module

* Uses `speech_recognition` with Google API
* Levenshtein threshold = 0.4 for matching

### ğŸ“¹ Detection Module

* Real-time with OpenCV & MediaPipe
* 15-frame buffer, 60% voting threshold
* Gemini integration for phrase interpretation

---

## âš ï¸ Limitations

* ğŸ§ Only 35 classes supported currently
* ğŸŒ Speech recognition needs internet
* ğŸ§  No dynamic sequence classification yet
* ğŸ“‰ Real-time inference may lag on low-end systems

---

## ğŸ”® Future Scope

* Expand sign vocabulary & phrases
* Add offline speech recognition
* Optimize inference on low-resource devices
* Dynamic sign sequences and sentence formation
* Improved accessibility & GUI UX

---

## ğŸ¤ Contributing

1. Fork the repo
2. Create a branch: `git checkout -b feature-name`
3. Commit: `git commit -m 'Add feature'`
4. Push: `git push origin feature-name`
5. Open a Pull Request

---

## ğŸ“œ License

MIT License â€“ see [LICENSE](./LICENSE)

---

## ğŸ™ Acknowledgments

* [MediaPipe](https://google.github.io/mediapipe/)
* [scikit-learn](https://scikit-learn.org/)
* [OpenCV](https://opencv.org/)
* [albumentations](https://albumentations.ai/)
* [Google Speech Recognition](https://pypi.org/project/SpeechRecognition/)
* [pyttsx3](https://pypi.org/project/pyttsx3/)
